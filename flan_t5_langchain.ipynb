{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader  #for textfiles\n",
    "from langchain.text_splitter import CharacterTextSplitter #text splitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings #for using HugginFace models\n",
    "from langchain.vectorstores import FAISS  \n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain.document_loaders import UnstructuredPDFLoader  #load pdf\n",
    "from langchain.indexes import VectorstoreIndexCreator #vectorize db index with chromadb\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import UnstructuredURLLoader  #load urls into docoument-loader\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csvfrom langchain.document_loaders import PyPDFLoader\n",
    "# Load the PDF file from current working directory\n",
    "loader = PyPDFLoader(\"./data/Designing and evaluating a big data analytics approach for predicting students’ success factors.pdf\")\n",
    "# Split the PDF into Pages\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# Define chunk size, overlap and separators\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=64,\n",
    "    separators=['\\n\\n', '\\n', '(?=>\\. )', ' ', '']\n",
    ")\n",
    "docs  = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mdrafsunsheikh/10784ce9-f796-443d-b973-fe6ae114c687/home/Study/Projects/llama_cpp/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      ".gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 1.49MB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 241kB/s]\n",
      "README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 5.01MB/s]\n",
      "config.json: 100%|██████████| 571/571 [00:00<00:00, 188kB/s]\n",
      "config_sentence_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 154kB/s]\n",
      "data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 194kB/s]\n",
      "pytorch_model.bin: 100%|██████████| 438M/438M [06:18<00:00, 1.16MB/s] \n",
      "sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 92.1kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 239/239 [00:00<00:00, 413kB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 658kB/s]\n",
      "tokenizer_config.json: 100%|██████████| 363/363 [00:00<00:00, 137kB/s]\n",
      "train_script.py: 100%|██████████| 13.1k/13.1k [00:00<00:00, 14.9MB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 529kB/s]\n",
      "modules.json: 100%|██████████| 349/349 [00:00<00:00, 458kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Embeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the vectorized db\n",
    "# Vectorstore: https://python.langchain.com/en/latest/modules/indexes/vectorstores.html\n",
    "from langchain.vectorstores import FAISS\n",
    "db = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mdrafsunsheikh/10784ce9-f796-443d-b973-fe6ae114c687/home/Study/Projects/llama_cpp/env/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The paper proposes a novel approach to predict student dropout using a dataset of mouse clicks, mouse movements, keystrokes and final marks.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm=HuggingFaceHub(repo_id=\"google/flan-t5-xxl\", model_kwargs={\"temperature\":1, \"max_length\":1000000})\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "#QUERYING\n",
    "query = \"Give me the summary of the paper?\"\n",
    "docs = db.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", \n",
    "retriever=db.as_retriever(search_kwargs={\"k\": 3}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Miah SJ, Kerr D, Hellens L'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who wrote the paper?\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
